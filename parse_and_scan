#!/bin/bash

source "$SCRIPT_DIR/fetch_website_content"

is_malicious() {
    local url=$1
    local signatures_file=$2
    jq -e --arg url "$url" '.malware[] | select(. == $url) // .trojans[] | select(. == $url) // .spyware[] | select(. == $url)' "$signatures_file" > /dev/null
    return $?
}

parse_and_scan() {
    local content=$1
    local signatures_file=$2

    # Use grep to extract all URLs
    echo "$content" | grep -Eo '(http|https)://[^"]+' | while read -r url; do
        if is_malicious "$url" "$signatures_file"; then
            echo "Malicious link found: $url"
        fi
    done
}

scan_website() {
    local url=$1
    local signatures_file=$2
    local content=$(fetch_website_content "$url")
    parse_and_scan "$content" "$signatures_file"
}
